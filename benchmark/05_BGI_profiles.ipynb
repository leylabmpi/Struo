{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute profile pipeline on BGI250 data\n",
    " \n",
    "The aim of this notebook is to run the metagenome profile pipeline using the defaults and the custom databases on real samples from the BGI250 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T08:15:52.616390Z",
     "start_time": "2019-09-11T08:15:52.219384Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ebio/abt3_projects/software/miniconda3_gt4.4/envs/py3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T08:15:56.036225Z",
     "start_time": "2019-09-11T08:15:56.031425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dirs\n",
    "work_dir = \"/ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark\"\n",
    "pipeline_folder = os.path.join(work_dir, \"bin/llmgp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.072195Z",
     "start_time": "2019-08-22T08:46:37.066384Z"
    }
   },
   "outputs": [],
   "source": [
    "# SGE out folders\n",
    "SGE_GTDB_dir = os.path.join(work_dir, \"tmp/SGE_out/llmgp/GTDB\")\n",
    "SGE_proGenomes_dir = os.path.join(work_dir, \"tmp/SGE_out/llmgp/progenomes\")\n",
    "SGE_Defaults_dir = os.path.join(work_dir, \"tmp/SGE_out/llmgp/defaults\")\n",
    "\n",
    "if not os.path.exists(os.path.join(work_dir, \"tmp/SGE_out/llmgp\")):\n",
    "    os.makedirs(SGE_GTDB_dir)\n",
    "    os.makedirs(SGE_proGenomes_dir)\n",
    "    os.makedirs(SGE_Defaults_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.080160Z",
     "start_time": "2019-08-22T08:46:37.074462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Profile out folders\n",
    "out_GTDB_dir = os.path.join(work_dir, \"data/profiles_BGI250/GTDB\")\n",
    "out_proGenomes_dir = os.path.join(work_dir, \"data/profiles_BGI250/progenomes\")\n",
    "out_Defaults_dir = os.path.join(work_dir, \"data/profiles_BGI250/defaults\")\n",
    "\n",
    "if not os.path.exists(os.path.join(work_dir, \"data/profiles_BGI250\")):\n",
    "    os.makedirs(out_GTDB_dir)\n",
    "    os.makedirs(out_proGenomes_dir)\n",
    "    os.makedirs(out_Defaults_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.088200Z",
     "start_time": "2019-08-22T08:46:37.082348Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_file = \"/ebio/abt3_projects2/databases_no-backup/TUK/metagenome/190100_TUK-all/samples_filt_BGI250.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.224266Z",
     "start_time": "2019-08-22T08:46:37.090435Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-- I/O --#\r\n",
      "# table with sample --> read_file information\r\n",
      "samples_file: tests/samples/samples_amy_n6.txt\r\n",
      "\r\n",
      "# output location\r\n",
      "output_dir: tests/output_amy_n6/\r\n",
      "\r\n",
      "# read file path\r\n",
      "## use \"None\" if full file path is included in the samples_file\r\n",
      "read_file_path: None\r\n",
      "\r\n",
      "#-- DB --#\r\n",
      "# NOTE: see the config_custom-db.yaml for using the progenomes db\r\n",
      "# humann2-associated databases\r\n",
      "genefamily_annotation_db: /ebio/abt3_projects2/databases_no-backup/humann2/utility_mapping/map_uniref90_name.txt.bz2\r\n",
      "humann2_nuc_db: /ebio/abt3_projects2/databases_no-backup/humann2/chocophlan/README.md\r\n",
      "humann2_prot_db: /ebio/abt3_projects2/databases_no-backup/humann2/uniref90_ec_filt/uniref90.ec_filtered.1.1.dmnd\r\n",
      "metaphlan2_pkl_db: /ebio/abt3_projects2/databases_no-backup/metaphlan2/mpa_v20_m200/mpa_v20_m200.pkl\r\n",
      "metaphlan2_bt2_db: /ebio/abt3_projects2/databases_no-backup/metaphlan2/mpa_v20_m200/mpa_v20_m200     # use the prefix for the *.bt2 files\r\n",
      "utility_mapping_db: /ebio/abt3_projects2/databases_no-backup/humann2/utility_mapping\r\n",
      "## kraken/bracken (db selected automatically based on read length)\r\n",
      "kraken_dbs:\r\n",
      "  150bp: /ebio/abt3_projects2/databases_no-backup/GTDB/release86/LLMGP-DB/kraken2/database150mers.kraken\r\n",
      "  100bp: /ebio/abt3_projects2/databases_no-backup/GTDB/release86/LLMGP-DB/kraken2/database100mers.kraken\r\n",
      "# taxonomy\r\n",
      "tax_dump: /ebio/abt3_projects/databases/Kraken/taxonkit/names.dmp\r\n",
      "\r\n",
      "#-- subsample --#\r\n",
      "# subsampling input reads \r\n",
      "## \"Skip\" skips subsampling; otherwise set the number of reads to subsample\r\n",
      "subsample_depth: Skip   \r\n",
      "subsample_seed: 18938\r\n",
      "\r\n",
      "#-- include read2 (if paired-end) --#\r\n",
      "# combine R1 & R2 or just use R1?\r\n",
      "include_read2: True\r\n",
      "\r\n",
      "#-- humann2 temporary files --#\r\n",
      "# remove the large temporary files generated by humann2?\r\n",
      "rm_humann2_tmp_files: True      \r\n",
      "\r\n",
      "#-- humann2 groupings --#\r\n",
      "# always have at least the \"*_default\" grouping\r\n",
      "humann2_regroup:\r\n",
      "  - uniref90_default\r\n",
      "  - uniref90_go\r\n",
      "  - uniref90_ko\r\n",
      "  - uniref90_eggnog\r\n",
      "  - uniref90_pfam\r\n",
      "  - uniref90_level4ec\r\n",
      "  - uniref90_infogo1000\r\n",
      "  - uniref90_rxn\r\n",
      "\r\n",
      "#-- software parameters --#\r\n",
      "# Use \"Skip\" to skip steps.\r\n",
      "# By skipping, you can run just humann2, kraken/bracken, and/or simka\r\n",
      "params:\r\n",
      "  # humann2\r\n",
      "  metaphlan2: -t rel_ab\r\n",
      "  humann2: --gap-fill on\r\n",
      "  humann2_db_in_memory: True        # copy databases to memory; less I/O, more memory\r\n",
      "  humann2_diamond: --sensitive --max-target-seqs 20 --block-size 3 --index-chunks 2\r\n",
      "  humann2_diamond_evalue: 1\r\n",
      "  reduce_taxonomic_profile: --function max --sort-by level\r\n",
      "  humann2_renorm_table: --units relab\r\n",
      "  # kraken/bracken (NOTE: dependent on read length)\r\n",
      "  kraken: \"\"        \r\n",
      "  bracken: -t 10 -l S        # species level (S); `-r` parameter set automatically\r\n",
      "  # simka\r\n",
      "  simka: -kmer-size 31 -abundance-min 2 -simple-dist -max-reads 1000000\r\n",
      "  simka_vis: -width 8 -height 8 -pca -heatmap\r\n",
      "  # hulk\r\n",
      "  hulk_histosketch: -k 21 -m 2\r\n",
      "  hulk_distance: \r\n",
      "    - jaccard\r\n",
      "    - braycurtis\r\n",
      "\r\n",
      "#-- snakemake pipeline --#\r\n",
      "## To use /tmp/global2/, see http://ilm.eb.local/user-guide/#Scratch-space-on-_002ftmp_002fglobal2\r\n",
      "pipeline:\r\n",
      "  snakemake_folder: ./\r\n",
      "  script_folder: ./bin/scripts/\r\n",
      "  temp_folder: /tmp/global2/      # your username will be added automatically to this path\r\n"
     ]
    }
   ],
   "source": [
    "# Note that I will use the cutsom HUMANn2 database, built using progenomes\n",
    "config_file = os.path.join(pipeline_folder, 'config_custom-db.yaml')\n",
    "#!cat $config_file\n",
    "config_file = os.path.join(pipeline_folder, 'config.yaml')\n",
    "!cat $config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.248219Z",
     "start_time": "2019-08-22T08:46:37.227117Z"
    }
   },
   "outputs": [],
   "source": [
    "config_default=\"\"\"#-- I/O --#\n",
    "# table with sample --> read_file information\n",
    "samples_file: {samples_file}\n",
    "\n",
    "# output location\n",
    "output_dir: {output_dir}\n",
    "\n",
    "# read file path\n",
    "## use \"None\" if full file path is included in the samples_file\n",
    "read_file_path: None\n",
    "\n",
    "#-- DB --#\n",
    "# NOTE: see the config_custom-db.yaml for using the progenomes db\n",
    "# humann2-associated databases\n",
    "genefamily_annotation_db: {genefamily_annotation_db}\n",
    "humann2_nuc_db: {humann2_nuc_db}\n",
    "humann2_prot_db: {humann2_prot_db}\n",
    "metaphlan2_pkl_db: /ebio/abt3_projects2/databases_no-backup/metaphlan2/mpa_v20_m200/mpa_v20_m200.pkl\n",
    "metaphlan2_bt2_db: /ebio/abt3_projects2/databases_no-backup/metaphlan2/mpa_v20_m200/mpa_v20_m200     # use the prefix for the *.bt2 files\n",
    "utility_mapping_db: /ebio/abt3_projects2/databases_no-backup/humann2/utility_mapping\n",
    "## kraken/bracken (db selected automatically based on read length)\n",
    "kraken_dbs:\n",
    "  150bp: {kraken_dbs_150}\n",
    "  100bp: {kraken_dbs_100}\n",
    "# taxonomy\n",
    "tax_dump: /ebio/abt3_projects/databases/Kraken/taxonkit/names.dmp\n",
    "\n",
    "#-- subsample --#\n",
    "# subsampling input reads \n",
    "## \"Skip\" skips subsampling; otherwise set the number of reads to subsample\n",
    "subsample_depth: 1000000\n",
    "subsample_seed: 18938\n",
    "\n",
    "#-- include read2 (if paired-end) --#\n",
    "# combine R1 & R2 or just use R1?\n",
    "include_read2: True\n",
    "\n",
    "#-- humann2 temporary files --#\n",
    "# remove the large temporary files generated by humann2?\n",
    "rm_humann2_tmp_files: True      \n",
    "\n",
    "#-- humann2 groupings --#\n",
    "# always have at least the \"*_default\" grouping\n",
    "humann2_regroup:\n",
    "  - uniref50_default\n",
    "  - uniref50_go\n",
    "  - uniref50_ko\n",
    "  - uniref50_eggnog\n",
    "  - uniref50_pfam\n",
    "  - uniref50_level4ec\n",
    "  - uniref50_infogo1000\n",
    "  - uniref50_rxn\n",
    "\n",
    "#-- software parameters --#\n",
    "# Use \"Skip\" to skip steps.\n",
    "# By skipping, you can run just humann2, kraken/bracken, and/or simka\n",
    "params:\n",
    "  # humann2\n",
    "  metaphlan2: -t rel_ab\n",
    "  humann2: --gap-fill on --diamond-2pass --search-mode uniref50 # --bypass-nucleotide-index \n",
    "  humann2_db_in_memory: Skip #True        # copy databases to memory; less I/O, more memory\n",
    "  humann2_diamond: --sensitive --max-target-seqs 20 --block-size 3 --index-chunks 2\n",
    "  humann2_diamond_evalue: 1\n",
    "  reduce_taxonomic_profile: --function max --sort-by level\n",
    "  humann2_renorm_table: --units relab\n",
    "  # kraken/bracken (NOTE: dependent on read length)\n",
    "  kraken: \"\"        \n",
    "  bracken:  -t 100 -l S        # species level (S); `-r` parameter set automatically\n",
    "  # simka\n",
    "  simka: Skip #-kmer-size 31 -abundance-min 2 -simple-dist -max-reads 1000000\n",
    "  simka_vis: Skip #-width 8 -height 8 -pca -heatmap\n",
    "  # hulk\n",
    "  hulk_histosketch: Skip #-k 21 -m 2\n",
    "  hulk_distance: \n",
    "    - jaccard\n",
    "    - braycurtis\n",
    "\n",
    "#-- snakemake pipeline --#\n",
    "## To use /tmp/global2/, see http://ilm.eb.local/user-guide/#Scratch-space-on-_002ftmp_002fglobal2\n",
    "pipeline:\n",
    "  snakemake_folder: ./\n",
    "  script_folder: ./bin/scripts/\n",
    "  temp_folder: /tmp/global2/      # your username will be added automatically to this path\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.276185Z",
     "start_time": "2019-08-22T08:46:37.250728Z"
    }
   },
   "outputs": [],
   "source": [
    "config_custom=\"\"\"# DESCRIPTION:\n",
    "## This is an example of running the pipeline with a custom humann2 db.\n",
    "## This config is set up to just use the custom nucleotide db, but the protein db could be used also (or instead)\n",
    "\n",
    "#-- I/O --#\n",
    "# table with sample --> read_file information\n",
    "samples_file: {samples_file}\n",
    "\n",
    "# output location\n",
    "output_dir: {output_dir}\n",
    "\n",
    "# read file path\n",
    "# use \"None\" if full file path is included in the samples_file\n",
    "read_file_path: None\n",
    "\n",
    "#-- DB --#\n",
    "## humann2 \n",
    "### custom humann2 databases\n",
    "humann2_nuc_db: {humann2_nuc_db}\n",
    "humann2_prot_db: {humann2_prot_db}\n",
    "### required humann2 database files (no need to change this)\n",
    "### To use UniRef90, change \n",
    "### genefamily_annotation_db: /ebio/abt3_projects2/databases_no-backup/humann2/utility_mapping/map_uniref90_name.txt.bz2\n",
    "genefamily_annotation_db: /ebio/abt3_projects2/databases_no-backup/humann2/utility_mapping/map_uniref50_name.txt.bz2\n",
    "metaphlan2_pkl_db: /ebio/abt3_projects2/databases_no-backup/metaphlan2/mpa_v20_m200/mpa_v20_m200.pkl\n",
    "metaphlan2_bt2_db: /ebio/abt3_projects2/databases_no-backup/metaphlan2/mpa_v20_m200/mpa_v20_m200     \n",
    "utility_mapping_db: /ebio/abt3_projects2/databases_no-backup/humann2/utility_mapping\n",
    "## kraken/bracken (db selected automatically based on read length)\n",
    "kraken_dbs:\n",
    "  150bp: {kraken_dbs_150}\n",
    "  100bp: {kraken_dbs_100}\n",
    "### NCBI taxonomy\n",
    "tax_dump: /ebio/abt3_projects2/databases_no-backup/GTDB/release86/LLMGP-DB/kraken2/taxonomy/names.dmp\n",
    "\n",
    "#-- subsample --#\n",
    "# subsampling input reads \n",
    "## \"Skip\" skips subsampling; otherwise set the number of reads to subsample\n",
    "subsample_depth: 1000000\n",
    "subsample_seed: 18938\n",
    "\n",
    "#-- include read2 (if paired-end) --#\n",
    "# combine R1 & R2 or just use R1?\n",
    "include_read2: True\n",
    "\n",
    "#-- humann2 temporary files --#\n",
    "# remove the large temporary files generated by humann2?\n",
    "rm_humann2_tmp_files: True      \n",
    "\n",
    "#-- humann2 groupings --#\n",
    "# always have at least the \"*_default\" grouping\n",
    "humann2_regroup:\n",
    "  - uniref50_default\n",
    "  - uniref50_go\n",
    "  - uniref50_ko\n",
    "  - uniref50_eggnog\n",
    "  - uniref50_pfam\n",
    "  - uniref50_level4ec\n",
    "  - uniref50_infogo1000\n",
    "  - uniref50_rxn\n",
    "\n",
    "#-- software parameters --#\n",
    "# Use \"Skip\" to skip steps.\n",
    "# By skipping, you can run just humann2, kraken/bracken, or simka\n",
    "params:\n",
    "  # humann2\n",
    "  metaphlan2: -t rel_ab  \n",
    "  humann2: --gap-fill on --bypass-nucleotide-index --diamond-2pass --search-mode uniref50\n",
    "  humann2_db_in_memory: Skip #True        # copy databases to memory; less I/O, more memory\n",
    "  humann2_diamond: --sensitive --max-target-seqs 20 --block-size 3 --index-chunks 2\n",
    "  humann2_diamond_evalue: 1\n",
    "  reduce_taxonomic_profile: --function max --sort-by level\n",
    "  humann2_renorm_table: --units relab\n",
    "  # kraken/bracken (NOTE: dependent on read length)\n",
    "  kraken: \"\"\n",
    "  bracken: -t 100 -l S        # species level (S); `-r` parameter set automatically\n",
    "  # simka \n",
    "  simka: Skip # -kmer-size 31 -abundance-min 2 -simple-dist -max-reads 1000000\n",
    "  simka_vis: Skip # -width 8 -height 8 -pca -heatmap\n",
    "  # hulk\n",
    "  hulk_histosketch: Skip # -k 21 -m 2\n",
    "  hulk_distance: \n",
    "    - jaccard\n",
    "    - braycurtis\n",
    "\n",
    "\n",
    "#-- snakemake pipeline --#\n",
    "pipeline:\n",
    "  snakemake_folder: ./\n",
    "  script_folder: ./bin/scripts/\n",
    "  temp_folder: /tmp/global2/        # your username will be added automatically to this path\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.284141Z",
     "start_time": "2019-08-22T08:46:37.278295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Config with GTDB databases\n",
    "config_GTDB = config_custom.format(samples_file = samples_file, \n",
    "                                   output_dir = out_GTDB_dir, \n",
    "                                   humann2_nuc_db = \"/ebio/abt3_projects2/databases_no-backup/GTDB/release86/LLMGP-DB/humann2/all_genes_annot.fna.gz\", \n",
    "                                   humann2_prot_db = \"/ebio/abt3_projects2/databases_no-backup/GTDB/release86/LLMGP-DB/humann2/all_genes.dmnd\", \n",
    "                                   kraken_dbs_150 = \"/ebio/abt3_projects2/databases_no-backup/GTDB/release86/LLMGP-DB/kraken2/database150mers.kraken\", \n",
    "                                   kraken_dbs_100 = \"/ebio/abt3_projects2/databases_no-backup/GTDB/release86/LLMGP-DB/kraken2/database100mers.kraken\") \n",
    "\n",
    "# Write config file\n",
    "config_GTDB_file = os.path.join(pipeline_folder, 'BGI250_GTDB.yaml')\n",
    "with open(config_GTDB_file, 'w') as outF:\n",
    "    outF.write(config_GTDB)\n",
    "#!cat $config_GTDB_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.292212Z",
     "start_time": "2019-08-22T08:46:37.286125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Config with proGenomes databases\n",
    "config_proGenomes = config_custom.format(samples_file = samples_file, \n",
    "                                   output_dir = out_proGenomes_dir, \n",
    "                                   humann2_nuc_db = \"/ebio/abt3_projects/databases/humann2_progenomes/progenomes_HUMANn2_UniRef.fna\", \n",
    "                                   humann2_prot_db = \"/ebio/abt3_projects/databases/humann2_progenomes/progenomes_HUMANn2.dmnd\", \n",
    "                                   kraken_dbs_150 = \"/ebio/abt3_projects/databases/Kraken/K2_Progenomes/Kraken/150mers/database150mers.kraken\", \n",
    "                                   kraken_dbs_100 = \"/ebio/abt3_projects/databases/Kraken/K2_Progenomes/Kraken/100mers/database100mers.kraken\")\n",
    "\n",
    "# Write config file\n",
    "config_proGenomes_file = os.path.join(pipeline_folder, 'BGI250_proGenomes.yaml')\n",
    "with open(config_proGenomes_file, 'w') as outF:\n",
    "    outF.write(config_proGenomes)\n",
    "#!cat $config_proGenomes_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.300137Z",
     "start_time": "2019-08-22T08:46:37.294289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Config with default databases\n",
    "# \"/ebio/abt3_projects2/databases_no-backup/humann2/uniref90_ec_filt/uniref90.ec_filtered.1.1.dmnd\"\n",
    "config_Defaults = config_default.format(samples_file = samples_file, \n",
    "                                        output_dir = out_Defaults_dir, \n",
    "                                        humann2_nuc_db = \"/ebio/abt3_projects2/databases_no-backup/humann2/chocophlan/README.md\", \n",
    "                                        humann2_prot_db = \"/ebio/abt3_projects2/databases_no-backup/humann2/uniref50/uniref50_annotated.1.1.dmnd\",\n",
    "                                        genefamily_annotation_db = \"/ebio/abt3_projects2/databases_no-backup/humann2/utility_mapping/map_uniref50_name.txt.bz2\",\n",
    "                                        kraken_dbs_150 = \"/ebio/abt3_projects/databases/Kraken/K2_Standard/150mers/database150mers.kraken\",\n",
    "                                        kraken_dbs_100 = \"/ebio/abt3_projects/databases/Kraken/K2_Standard/100mers/database100mers.kraken\")\n",
    "\n",
    "\n",
    "# Write config file\n",
    "config_Defaults_file = os.path.join(pipeline_folder, 'BGI250_Defaults.yaml')\n",
    "with open(config_Defaults_file, 'w') as outF:\n",
    "    outF.write(config_Defaults)\n",
    "#!cat $config_Defaults_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare snakemake command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.308134Z",
     "start_time": "2019-08-22T08:46:37.302085Z"
    }
   },
   "outputs": [],
   "source": [
    "# GTDB\n",
    "#conda_env = 'conda activate snakemake'\n",
    "conda_env = 'conda activate snakemake_dev'\n",
    "P_cmd = \"cd {llmgqc} && {conda_env} && screen -L -S BGI_llmgp {exe} {config_file} \\\n",
    "    cluster.json {SGE_out} {jobs} \\\n",
    "    --keep-going --rerun-incomplete --dryrun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.316188Z",
     "start_time": "2019-08-22T08:46:37.310180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp && conda activate snakemake_dev && screen -L -S BGI_llmgp ./snakemake_sge.sh /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/BGI250_GTDB.yaml     cluster.json /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/tmp/SGE_out/llmgp/GTDB 5     --keep-going --rerun-incomplete --dryrun\n"
     ]
    }
   ],
   "source": [
    "GTDB_cmd = P_cmd.format(conda_env = conda_env, \n",
    "                        llmgqc = pipeline_folder,  \n",
    "                        exe = './snakemake_sge.sh', \n",
    "                        config_file = config_GTDB_file, \n",
    "                        SGE_out = SGE_GTDB_dir, \n",
    "                        jobs = 5)\n",
    "print(GTDB_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.324206Z",
     "start_time": "2019-08-22T08:46:37.318228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp && conda activate snakemake_dev && screen -L -S BGI_llmgp ./snakemake_sge.sh /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/BGI250_proGenomes.yaml     cluster.json /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/tmp/SGE_out/llmgp/progenomes 10     --keep-going --rerun-incomplete --dryrun\n"
     ]
    }
   ],
   "source": [
    "proGenomes_cmd = P_cmd.format(conda_env = conda_env, \n",
    "                        llmgqc = pipeline_folder,  \n",
    "                        exe = './snakemake_sge.sh', \n",
    "                        config_file = config_proGenomes_file, \n",
    "                        SGE_out = SGE_proGenomes_dir, \n",
    "                        jobs = 10)\n",
    "print(proGenomes_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T08:46:37.332186Z",
     "start_time": "2019-08-22T08:46:37.326269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp && conda activate snakemake_dev && screen -L -S BGI_llmgp ./snakemake_sge.sh /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/BGI250_Defaults.yaml     cluster.json /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/tmp/SGE_out/llmgp/defaults 20     --keep-going --rerun-incomplete --dryrun\n"
     ]
    }
   ],
   "source": [
    "Defaults_cmd = P_cmd.format(conda_env = conda_env, \n",
    "                        llmgqc = pipeline_folder,  \n",
    "                        exe = './snakemake_sge.sh', \n",
    "                        config_file = config_Defaults_file, \n",
    "                        SGE_out = SGE_Defaults_dir, \n",
    "                        jobs = 20)\n",
    "print(Defaults_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T08:16:00.788293Z",
     "start_time": "2019-09-11T08:16:00.654359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/bowtie2.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- pigz\r\n",
      "- bioconda::samtools\r\n",
      "- bioconda::bedtools\r\n",
      "- bioconda::bowtie2\r\n",
      "\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/compress.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- pigz\r\n",
      "- bioconda::dsrc\r\n",
      "\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/fastqc.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- bioconda::fastqc\r\n",
      "\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/hadley.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "dependencies:\r\n",
      "- conda-forge::r-ape\r\n",
      "- conda-forge::r-dplyr\r\n",
      "- conda-forge::r-tidyr\r\n",
      "- conda-forge::r-ggplot2\r\n",
      "\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/hulk.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- pigz\r\n",
      "- bioconda::hulk\r\n",
      "\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/humann2.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- pigz\r\n",
      "- conda-forge::glpk=4.65\r\n",
      "- bioconda::bowtie2=2.3.4.1\r\n",
      "- bioconda::humann2=0.11.1\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/kraken.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- pigz\r\n",
      "- bioconda::taxonkit\r\n",
      "- bioconda::kraken2\r\n",
      "- bioconda::bracken=2.2\r\n",
      "\r\n",
      "\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/multiqc.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- bioconda::multiqc\r\n",
      "\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/read_combine.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- pigz\r\n",
      "- bioconda::bioawk\r\n",
      "- bioconda::seqtk\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/samtools.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- pigz\r\n",
      "- bioconda::samtools\r\n",
      "\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/simka.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- pigz\r\n",
      "- conda-forge::r-dendextend\r\n",
      "- conda-forge::r-gplots\r\n",
      "- bioconda::simka\r\n",
      "\r\n",
      "==> /ebio/abt3_projects/small_projects/jdelacuesta/DBs_benchmark/bin/llmgp/bin/envs/skewer.yaml <==\r\n",
      "channels:\r\n",
      "- conda-forge\r\n",
      "- bioconda\r\n",
      "dependencies:\r\n",
      "- pigz\r\n",
      "- bioconda::skewer\r\n"
     ]
    }
   ],
   "source": [
    "sessionInfo = \"find {0} -name '*.yaml' | xargs head -n 1000\".format(os.path.join(pipeline_folder, 'bin', 'envs'))\n",
    "!$sessionInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
